
\section{Using Attribute Grammars to Generate Test Cases}
\label{attrgram}

Statistically driven algorithms for context free grammars can generate examples
which mimic an input corpus from the perspective of the probability
distributions. However, even though CFG algorithms will still generate many
invalid inputs. These inputs while \textit{syntactically} correct are
\textit{semantically} incorrect. To address this issue we add semantic
constraints using attribute grammars.

\subsection{Attribute Grammars}

An attribute grammar\footnote{Sometimes these are referred to as attributed
grammars} adds context sensitive constraints onto a context free grammar.
These constraints are added by attaching to each grammar rule an option
``action'' statement and ``condition'' statement. The reader may be familiar
with attribute grammars containing only action statements (and no condition
statements) from using parser generators such as Yacc. For example the following
grammar computes the value of a simple arithmetic expression using an attributed
grammar:

\begin{verbatim}
Term -> Term PLUS Factor
        with Action {
          Term{1}.value = Term{2}.value + Factor.value
        }
      | Term DASH Factor
        with Action {
          Term{1}.value = Term{2}.value - Factor.value
        }
      | Factor
        with Action {
          Term{1}.value = Factor.value
        }
      ;
Factor -> NUMBER 
          with Action {
            Factor.value = NUMBER
          }
        ;
\end{verbatim}

\noindent
all the attributes in this example are \textit{synthesized} attributes.
Synthesized attributes are computed from the bottom up. In contrast inherited
attributes are computed from the top down.\cite{Aho2007}

\begin{figure*}
  \begin{center}
    \subfigure[CFG Parse]{
      \includegraphics[scale=0.3]{figs/ast_1.png}
      \label{ast_1}
    }
    \subfigure[Attributed CFG Parse]{
      \includegraphics[scale=0.3]{figs/ast_2.png}
      \label{ast_2}
    }
  \end{center}
  \caption{Parse trees for ``3+5''}
  \label{asts}
\end{figure*}

To understand how the grammar works an example is in order. Consider the
sentence ``3+5'' whose parse trees are given in figure \ref{asts}. The context
free parse, figure \ref{ast_1}, shows the structure of a bottom up parse of the
example. Executing the actions annotates the parse tree and produces the second
parse tree, figure \ref{ast_2}.\footnote{this is sometimes called syntax
directed translation} 

Attribute grammars of this form are often used as part of a compilation tool
chain. Indeed, they were originally designed with such a purpose in mind.
However, when conditions are added attribute grammar describe can describe
context sensitive restrictions.\cite{Slonneger1995} As an example, lets add a
constraint to our example grammar to prevent terms from holding negative values:

\begin{verbatim}
Term -> Term PLUS Factor
        with Action {
          Term{1}.value = Term{2}.value + Factor.value
        }
      | Term DASH Factor
        with Action {
          Term{1}.value = Term{2}.value - Factor.value
        }
        with Condition {
          Term{2}.value >= Factor.value
        }
      | Factor
        with Action {
          Term{1}.value = Factor.value
        }
      ;
Factor -> NUMBER 
          with Action {
            Factor.value = NUMBER
          }
        ;
\end{verbatim}

\noindent
A ``condition'' clause was added to the rule ``Term $\rightarrow$ Term DASH
Factor'' which checks to make sure the ``Term'' is always greater or equal to
the Factor. When this condition is false a parse error would occur during a
parse. For example the sentence ``5 - 10'' would no longer parse.

\subsection{Generating Strings from Attribute Grammars}

To use attribute grammars in the context of test case generation on needs to
generate strings in the language rather than recognize them (as in parsing).
Unfortunately, generating strings from attribute grammars is a harder problem
than parsing. In general parsing strings using context free grammars can be done
in polynomial time (by push down automata).\cite{Aho2007} However, depending on
the language allowed in the actions and conditions \textit{generating} a string
could be undecidable. When the conditions are restricted to propositional
statements and the actions are restricted to assignments, if-then, and
if-then-else statements the problem is NP-Hard. Appendix \ref{hard} contains a
proof that Attribute Grammar String Generation (AGSG) belongs to the class
NP-Complete.

Our program ``Fuzzbuzz'' implements string generation from attribute grammars
and it does so in a top down manner. It starts at the start symbol and
stochastically choose a rule to apply at for each Non-Terminal. If a rule has a
condition associated with it checks whether or not it is satisfiable. If the
condition is satisfiable but contains free variables (which is the common case)
a constraint is generated which is passed down to its children. The constraints
are applied and chained together with future actions and conditions. When it
comes time for a rule to be finalized the associate actions are executed and the
variables created are propagated to the parent. Given the complexity of the
algorithm further details are left for the adventurous reader in the source of
the program.\footnote{github.com/timtadh/fuzzbuzz}

\subsection{Related Work}

Modern work on generation of strings from context free grammars for use in
automated test case generation can be traced back to the algorithm due to
Purdom.\cite{Purdom1972} Purdom's algorithm was designed specifically to test
LR(1) parsers and as such was unconcerned with the semantics of a language. It
particular Purdom hoped to catch bugs related to the automate parser generator
construction. Our concerns our more broad, we hope to identify faults throughout
a software system, not just faults in the parser. Therefore, we cannot ignore
the semantics of a language.

Ten years later Duncan and Hutchinson became interested in using the attribute
grammar formalism for use in creating testable specifications.\cite{Duncan1981}
Duncan and Hutchinson's goal was to create a formal way of specifying the input
and output languages of a program. They then used these specifications to test
the program for conformance to the predefined specifications. They created two
test case generation algorithms. In one version they choose which grammar rule
to apply ``random'' or based on user supplied heuristics. In another version all
choices are predetermined to enable systematic enumeration of test cases from
the grammar.

The difficulty in Duncan and Hutchinson's algorithm (as with all attribute
grammar string generation algorithms) comes with processing the actions and
conditions. In their terminology actions are actions but conditions are termed
``guards'' (as in they guard the application of a grammar rule). Duncan and
Hutchinson attribute their use of guards to Milton whose 1979 paper discusses
parsing LL(k) attributed grammars.\cite{Milton1979}

