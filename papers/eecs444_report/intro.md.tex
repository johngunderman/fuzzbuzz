
Attribute Grammars were invented in the heady days of the late 1960's by Dr.
Knuth.\cite{Knuth1990} At the time the question on how to formally define the
semantics of a programming language had become a fashionable research topic.
Attribute grammars emerged as a popular way and remain important for such
purposes today. The key to their success is the ability to define context
sensitive semantics in languages. A common example, variable names must be
declared before use.

Input Languages to programs are often context sensitive. The obvious and natural
example is computer programming languages which encompass a wide variety of
useful programs. Web browsers, text editors, integrated development
environments, web servers, and game engines all make use of programming
languages. Sometimes exposing the languages to the end user for extensibility
purposes. Other program types have similarly complex input schemes often arising
from natural world, for example organic chemical structures.

Fuzzing, in particular ``Blackbox Fuzzing'' automatically generates test cases
for software. In the simplest formulation the test cases are little more than
random data. These types of tests produce poor coverage of the target program.
Context free grammar based fuzzing produces better results. However, context
free grammars are still unable to achieve good coverage of the entire target
program. 

Why do context free grammars fail when used to generate test cases for software
even when the grammar is known (and not inferred)? Context free grammars only
capture the syntax of the language and not the semantics. This means, the
language the program accepts as input is strictly a subset of the language the
CFG generates. Depending on the size of the gap between the CFG and the actual
language a random string generated from the CFG may only have a very small
chance of being in the language.

The generated inputs can be improved by adding semantic awareness to the
generation system. The semantics, or meaning, of a language fragments are often
context dependent. Thus, to capture semantics one needs a more powerful
formalism than context free grammars; attribute grammars are one such formalism.

Attribute grammars extend the syntax of context free grammars by adding
``actions'' and ``conditions'' to grammar rules. Actions specify create and
transform variables attached to Non-Terminal symbols while conditions act as
guards on specific grammar rules. The conditions prevent grammar rules from
being applied unless the condition evaluates to true. In essence attribute
grammars further \textit{restrict} the language defined by the context free
grammar. 

Since attribute grammars are extensions of context free grammars the attribute
grammar generative algorithm is based on the generative algorithm for context
free grammars. Therefore, in section \ref{cfgstats} we discuss the details and
history of generating strings from context free grammars, in section
\ref{attrgram} the details and complications of attribute grammars are
described, and finally in section \ref{mutation} we discuss grammar driven
example mutation. While the paper title refers to ``inferred'' attribute
grammars, the inference aspect remains future work. 

