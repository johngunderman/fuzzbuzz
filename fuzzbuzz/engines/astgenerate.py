#!/usr/bin/env python
# -*- coding: utf-8 -*-
#Author: John Gunderman
#Email: johngunderman@gmail.com
#For licensing see the LICENSE file in the top level directory.

from ply import yacc

from reg import registration
from fuzzbuzz.models.symbols import Terminal, NonTerminal
from fuzzbuzz.frontend.lexer import tokens, Lexer
from fuzzbuzz.frontend.ast   import Node

class NoExampleException(Exception):
    pass

@registration.register(
    {'example_list':'examples',
     'lexer':'lexer_class'},
    'Generates an AST in serialized form for the given inputs')
def ast_generator(rlexer, grammar, example_list=None, lexer=None):

    if not lexer:
        return None, 'AST Generator requires a lexer'
    if not example_list:
        return None, 'AST Generator requires at least one example'

    lex = lexer()

    def generate_examples_ast(parser, example_list):
        """Generates an AST for each example provided in `example_list`.
        This AST is parsed according to the grammar in `grammar`.

        @param parser : The parser from which the ASTs will be generated from
        @param example_list : the strings for which ASTs will be generated
        @return list of ASTs, corresponding to the examples provided.
        """
        ast_list = list()

        for example in example_list:
            ast_list.append(str(generate_ast(example, parser)))

        return ast_list

    def generate_ast(example, parser):
        """Generates and returns an AST for the provided `example`
        AST generated according to the provided grammar

        @param example : the text to be parsed into an AST
        @param parser  : the parser from which the ASTs will be generated from
        @return an AST object
        """

        result = parser.parse(example, lex)
        return result

    def generate_parser(grammar):
        """Generate a parser for our `example_list` based on the grammar in
        `grammar`. This is probably going to be very hacky.
        On completion this function returns a `parser` object which can be
        used to generate ASTs for our examples.

        @param grammar_start : The start symbol for the grammar we are to
                               generate a parser for
        """
        for sym in grammar.nonterminals.itervalues():
            for rule in sym.ply():
                ParserGenerator.add_production(rule)

        return ParserGenerator(lexer.tokens)

    parser = generate_parser(grammar)
    ast_list = generate_examples_ast(parser, example_list)
    return ast_list, None


class ParserGenerator(object):
    """Generate a yacc (ply) parser for the given input strings
    """

    # production counter
    pcount = 0

    # hackity hack, parser has to start with 'Stmts' as top rule for this to work
    start = 'Stmts'

    def __new__(cls, tokens,  **kwargs):
        # get the tokens from the lexer into the scope of our parser.
        setattr(cls, 'tokens', tokens)
        self = super(ParserGenerator, cls).__new__(cls, **kwargs)
        # TODO: allow us to have multiple generated tab files
        # otherwise we waste extra time re-generating the parser.
        self.yacc = yacc.yacc(module=self,  tabmodule="generated_parser_tab", **kwargs)
        return self.yacc

    @classmethod
    def add_production(cls, prod_string):
        func = cls.ply_func_for(prod_string)
        prod_name = prod_string.split(' ')[0]
        func_name = 'p_' + prod_name + str(cls.pcount)
        cls.pcount += 1
        setattr(cls, func_name, func)

    @classmethod
    def ply_func_for(cls, docstring):
        """Returns an anonymous function which has the supplied docstring

        @param docstring : the docstring for the returned anonymous function
        @return an anonymous function
        """
        def ply_make_tree(t, docstring):
            """Where t is a production generated by ply, give t[0] a new node
            with child nodes t[1..n]

            @param t : (list) where t[0] is the left-hand side of the production
            generated by ply, and t[0..n] is the right-hand side.

            @param docstring : (string) the production rule for this function
            """
            # TODO: figure out what to label things
            prod = docstring.split(' ')
            # We can only have one thing on the left side of our prod, so
            i = 2               # (first is prod, second is ':')

            # this gives us a node with the name of the production
            n = Node(prod[0])
            for x in range(i, len(prod)):
                if isinstance(t[x-1], Node):
                    n.addkid(t[x-1])
                else:
                    n.addkid(Node(prod[x] + ':' + str(t[x-1])))

            t[0] = n

        f = lambda s, t : ply_make_tree(t, docstring)
        f.__doc__ = docstring
        return f

    def p_error(self, t):
        # TODO: we need a better exception framework
        if t is None:
            return

        print "Syntax error at the following token:"
        print t
        raise Exception
